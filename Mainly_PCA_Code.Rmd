---
title: "Mainly PCA"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(ISLR)
library(pls)
library(glmnet)
library(RColorBrewer)
library(coefplot)
```

Note that all the below code only focused on math test scores. We could either do math and reading separate or just used the dataset that pools math and reading together (that will be a very easy switch if we do decide to pool them). The dataset that is the same as ours but also pools by subject is seda_state_pool_gcs_4.0.
```{r}
# Official Data
test_data = read_csv("https://stacks.stanford.edu/file/druid:db586ns4974/seda_state_poolsub_gcs_4.0.csv")
state_info = read_csv("https://stacks.stanford.edu/file/druid:db586ns4974/seda_cov_state_pool_4.0.csv")
```

```{r}
# Arranging math scores from highest to lowest for each state for comparison with other variables (just by looking at data)
test_data %>% filter(subcat == "all") %>% 
  inner_join(state_info, by = "stateabb") %>%
  arrange(gcs_mn_avg_mth_ol)
```
Just by manually looking at the above data, I notice the following trends:
* Higher percent of whites (asian?) in state have higher test scores; Higher percent of other races in state have lower test scores
* Higher percent of ECD in state have lower test scores
* More people on free/reduced lunch mean lower test scores
* Lower SES composite in state leads to lower test scores
* Possibly higher hswhtblk/rswhtblk means lower scores? (less obvious)

```{r}
# Joining the two datasets and selected only the most "important" variables to include in the dataset (can add more later if we want)
# This is the data used for essentially all the MATH code below
state_info_condensed = state_info %>% 
  select(c(1:11, 14, 17:26, 47:50))
test_state_data_mth = test_data %>% filter(subcat == "all") %>% 
  select(c("fips", "stateabb", "gcs_mn_avg_mth_ol")) %>%
  inner_join(state_info_condensed, by = c("fips", "stateabb"))
```


```{r}
# lm Model for math, excluding fips and stateabb in the model since thats not important
lm_model_mth = lm(gcs_mn_avg_mth_ol ~ ., data = test_state_data_mth[, -c(1,2)])
summary(lm_model_mth)
```
Note all the highly insignificant pvalues above because of our multicollinearity. We have multicollinearity since, for example, we have a separate column for the percent of each race in the state which are clearly all very correlated since all the proportions would add roughly to 1.



```{r fig.height=7}
# Principal Component Analysis (PCA) and plot for math
test_state_PCA_mth = test_state_data_mth %>%
  column_to_rownames("stateabb")
test_state_PCA_mth = test_state_PCA_mth[-52,-1]
set.seed(1000)
pcr_model_mth = prcomp(test_state_PCA_mth, scale=TRUE)
summary(pcr_model_mth)
biplot(pcr_model_mth,scale=0, cex=.7)
```
The interpretation for this plot (I think) is that notice the arrow for math test scores is pointing upward Therefore, any other variable pointing upwards indicates a positive correlation (hence SES composite, percent white, etc.). Meanwhile, the arrows pointing the opposite direction indicate that those variables are negatively correlated with math test scores (hence percent economically disadvantages, percent black, percent free lunch are most obvious). *** Note that these trends follow what was originally found just by manually examining the data, so thats a good sign.

The regions csv data came from this link: https://www.kaggle.com/omer2040/usa-states-to-region so youll have to download it.
```{r fig.height=7, fig.width=5}
# The same PCA but now making it so we can color the plot according to which region the US state is located
# library(devtools)
# install_github("vqv/ggbiplot")
library(ggbiplot)
us_regions = read.csv("./states.csv")
# Adding the region data to our data for this part
test_state_PCA_mth2 = test_state_data_mth[-52,-1] %>%
  inner_join(select(us_regions, stateabb = State.Code, Region), by = "stateabb")
# Making each state as the row name
test_state_PCA_mth2 = test_state_PCA_mth2 %>% 
  column_to_rownames("stateabb")
# PCA and plot by region for math
set.seed(1000)
pcr_model_mth2 = prcomp(test_state_PCA_mth2[,-26], scale=TRUE)
ggbiplot(pcr_model_mth2, ellipse=TRUE,  labels=rownames(test_state_PCA_mth2), groups=test_state_PCA_mth2[,26]) +
  theme(legend.position="bottom")
```
From the plot above, we are seeing the South consistently has lower test scores than any other region. Other regional patterns are harder to describe but you can note them above.

The following is just an example code from online at the URL https://cmdlinetips.com/2019/04/introduction-to-pca-with-r-using-prcomp/ to help build the PCA above
```{r}
# gapminder_w_url <- "https://bit.ly/2vEDq5b"
# # read the data into dataframe
# gapminder_wide <- read_csv(gapminder_w_url)
# # first3 rows
# head(gapminder_wide, n=3)
# gapminder_life <- gapminder_wide %>%
#   filter(continent %in% c("Africa","Europe")) %>%
#   select(continent,country,starts_with('lifeExp'))
# gapminder_life <- gapminder_life %>% 
#   unite("continent_country", c(continent,country)) %>%
#   column_to_rownames("continent_country")
# pca_res <- prcomp(gapminder_life, scale=TRUE)
# summary(pca_res)
# pca_res$x[,1:3]
```

PCA for RLA test scores
```{r}
# This is the data used for essentially all the RLA code below
state_info_condensed = state_info %>% 
  select(c(1:11, 14, 17:26, 47:50))
test_state_data_rla = test_data %>% filter(subcat == "all") %>% 
  select(c("fips", "stateabb", "gcs_mn_avg_rla_ol")) %>%
  inner_join(state_info_condensed, by = c("fips", "stateabb"))
```

```{r fig.height=7}
# PCA and plot for RLA
test_state_PCA_rla = test_state_data_rla %>%
  column_to_rownames("stateabb")
test_state_PCA_rla = test_state_PCA_rla[-52,-1]
set.seed(1000)
pcr_model_rla = prcomp(test_state_PCA_rla, scale=TRUE)
summary(pcr_model_rla)
biplot(pcr_model_rla,scale=0, cex=.7)
```

```{r fig.height=7, fig.width=5}
# # The same PCA but now making it so we can color the plot according to which region theUS state is located
# library(devtools)
# install_github("vqv/ggbiplot")
library(ggbiplot)
us_regions = read.csv("./states.csv")
# Adding the region data to our data for this part
test_state_PCA_rla2 = test_state_data_rla[-52,-1] %>%
  inner_join(select(us_regions, stateabb = State.Code, Region), by = "stateabb")
# Making each state as the row name
test_state_PCA_rla2 = test_state_PCA_rla2 %>% 
  column_to_rownames("stateabb")
# PCA and plot by region for rla 
set.seed(1000)
pcr_model_rla2 = prcomp(test_state_PCA_rla2[,-26], scale=TRUE)
ggbiplot(pcr_model_rla2, ellipse=TRUE,  labels=rownames(test_state_PCA_rla2), groups=test_state_PCA_rla2[,26])+
  theme(legend.position="bottom")
```




PCA for pooled test scores AND taking our response variable (test score) out of the PCA since I don't think it's supposed to be in it.
```{r}
# Official Pooled Data
pooled_test_data = read_csv("https://stacks.stanford.edu/file/druid:db586ns4974/seda_state_pool_gcs_4.0.csv")
state_info = read_csv("https://stacks.stanford.edu/file/druid:db586ns4974/seda_cov_state_pool_4.0.csv")
```

```{r}
# Condensed Pooled Data
state_info_condensed = state_info %>% 
  select(c(1:11, 14, 17:26, 47:50))
test_state_data = pooled_test_data %>% filter(subcat == "all") %>% 
  select(c("fips", "stateabb", "gcs_mn_avg_ol")) %>%
  inner_join(state_info_condensed, by = c("fips", "stateabb"))
```

```{r}
# lm Model for Pooled Data
lm_model = lm(gcs_mn_avg_ol ~ ., data = test_state_data[, -c(1,2)])
summary(lm_model)
```

```{r fig.height=7}
# PCA and plot for Pooled Data
test_state_PCA = test_state_data %>%
  column_to_rownames("stateabb")
test_state_PCA = test_state_PCA[-52,c(-1,-2)]
set.seed(1000)
pcr_model = prcomp(test_state_PCA, scale=TRUE)
summary(pcr_model)
pcr_model$x
biplot(pcr_model, scale=0, cex=.7)
# Determining number of components
pcr_model$sdev^2
screeplot(pcr_model, type="line")
```
First 10 principal components give 95% variability. Otherwise Kaiser's criteria and scree plot says only use the first five.

```{r}
# The same PCA but now making it so we can color the plot according to which region the US state is located
library(ggbiplot)
us_regions = read.csv("./states.csv")
# Adding the region data to our data for this part
test_state_PCA2 = test_state_data[-52,-1] %>%
  inner_join(select(us_regions, stateabb = State.Code, Region), by = "stateabb")
# Making each state as the row name
test_state_PCA2 = test_state_PCA2 %>% 
  column_to_rownames("stateabb")
# PCA and plot by region for pooled data
set.seed(1000)
pcr_model2 = prcomp(test_state_PCA2[,c(-1,-26)], scale=TRUE)
ggbiplot(pcr_model2, ellipse=TRUE,  labels=rownames(test_state_PCA2), groups=test_state_PCA2[,26]) +
  theme(legend.position="bottom")
```

```{r}
# Variamax rotation on pooled PCA data for easier interpretations (10 and 5 components)
varimax(pcr_model$rotation[, 1:10])
varimax(pcr_model$rotation[, 1:5])
```


```{r}
# library(ggplot2)
# ggplot(test_state_data, aes(x=perhsp, y=urban)) + geom_point()
# ggplot(test_state_data, aes(x=perwht, y=urban)) + geom_point()
# ggplot(test_state_data, aes(x=perhsp, y=rural)) + geom_point()
# ggplot(test_state_data, aes(x=perwht, y=rural)) + geom_point()
# 
# ggplot(test_state_data, aes(x=perhsp, y=hswhthsp)) + geom_point()
# ggplot(test_state_data, aes(x=perwht, y=hswhthsp)) + geom_point()
# 
# ggplot(test_state_data, aes(x=perhsp, y=sesavgall)) + geom_point()
# ggplot(test_state_data, aes(x=perwht, y=sesavgall)) + geom_point()
# 
# ggplot(test_state_data, aes(x=rural, y=hswhthsp)) + geom_point()
# ggplot(test_state_data, aes(x=urban, y=hswhthsp)) + geom_point()
```


```{r}
# PCA using tidymodels
library("tidymodels")
library("tidytext")
library("ggrepel")

# Remove PR since it is missing a lot of racial data
# We won't need fips codes either
test_state_PCA_mth = test_state_data_mth %>% 
  filter(stateabb != "PR") %>%  #& stateabb != "DC") %>% 
  select(-fips)

# Create recipe for the pca
pca_rec <- recipe(~., data = test_state_PCA_mth) %>%
  update_role(stateabb, gcs_mn_avg_mth_ol, new_role = "id") %>%
  step_normalize(all_predictors()) %>% # Probably don't need this step
  step_pca(all_predictors())

# Actually perform the pca
pca_prep <- prep(pca_rec)

# Calculate sd and variation
sdev <- pca_prep$steps[[2]]$res$sdev

percent_variation <- sdev^2 / sum(sdev^2)

var_df <- data.frame(PC=paste0("PC",1:length(sdev)),
                     var_explained=percent_variation,
                     stringsAsFactors = FALSE)

# Plot the variation explained by each PC
var_df %>%
  mutate(PC = fct_inorder(PC)) %>%
  ggplot(aes(x=PC,y=var_explained))+geom_col()


# Plot the composition of the top 5 PCs
tidied_pca <- tidy(pca_prep, 2)

tidied_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  mutate(component = fct_inorder(component)) %>%
  ggplot(aes(value, terms, fill = terms)) +
    geom_col(show.legend = FALSE) +
    facet_wrap(~component, nrow = 1) +
    labs(y = NULL)

# Re-plot, but order by decreasing absolute value
tidied_pca %>%
  filter(component %in% paste0("PC", 1:5)) %>%
  mutate(terms = reorder_within(terms, abs(value), component)) %>% 
ggplot(aes(value, terms, fill = terms)) +
  geom_col(show.legend = FALSE) +
  facet_wrap(~ component, scales = "free_y", nrow = 1) +
  scale_y_reordered() +
  labs(y = NULL) +
  theme(axis.text = element_text(size = 7))

# Plot the first two PCs and color by the math scores
# Note that pca_prep$template is equivalent to juice(pca_prep)
ggplot(pca_prep$template, aes(x = PC1, y = PC2)) +
  geom_point(aes(col = gcs_mn_avg_mth_ol), alpha = 0.75, size = 1.5) +
  geom_text_repel(aes(label = stateabb), size = 3) +
  scale_color_viridis_c(option = "magma")
```